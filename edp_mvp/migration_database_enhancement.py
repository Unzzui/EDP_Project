#!/usr/bin/env python3
"""
üéØ MIGRACI√ìN CR√çTICA: Conversi√≥n de Pagora MVP a Herramienta de Inteligencia Operacional

Este script implementa los cambios estructurales cr√≠ticos que transforman la base de datos
de un simple tracker transaccional a una plataforma de inteligencia operacional completa.

CAMBIOS CR√çTICOS IMPLEMENTADOS:
- Correcci√≥n de tipos monetarios (BIGINT ‚Üí DECIMAL)
- Tabla de historial de estados autom√°tico
- Perfiles de clientes para an√°lisis predictivo
- Tracking temporal granular
- KPI snapshots para an√°lisis de tendencias
- Triggers autom√°ticos para consistencia de datos
- √çndices de performance optimizados

Autor: Pagora MVP Enhancement Team
Fecha: 2025-01-28
"""

import os
import sys
import logging
from datetime import datetime
from typing import Dict, List, Any
import traceback

# A√±adir el directorio de la aplicaci√≥n al path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from app.config import get_config
from app.extensions import db
from flask import Flask

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('migration_enhancement.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DatabaseEnhancementMigration:
    """Migraci√≥n para transformar la BD en herramienta de inteligencia operacional."""
    
    def __init__(self, app):
        self.app = app
        self.config = get_config()
        
    def run_migration(self):
        """Ejecutar migraci√≥n completa con todos los cambios cr√≠ticos."""
        logger.info("üöÄ INICIANDO MIGRACI√ìN CR√çTICA DE BASE DE DATOS")
        logger.info("Transformando Pagora MVP en herramienta de inteligencia operacional...")
        
        try:
            with self.app.app_context():
                # Paso 1: Backup de seguridad
                self._create_backup()
                
                # Paso 2: Modificar tablas existentes (tipos monetarios cr√≠ticos)
                self._fix_monetary_types()
                
                # Paso 3: Agregar campos de tracking temporal granular
                self._add_temporal_tracking_fields()
                
                # Paso 4: Crear tabla de historial de estados (CR√çTICA)
                self._create_edp_status_history_table()
                
                # Paso 5: Crear tabla de perfiles de clientes (an√°lisis predictivo)
                self._create_client_profiles_table()
                
                # Paso 6: Enriquecer tabla de proyectos
                self._enhance_projects_table()
                
                # Paso 7: Mejorar tablas de costos
                self._enhance_cost_tables()
                
                # Paso 8: Crear tabla de KPI snapshots
                self._create_kpi_snapshots_table()
                
                # Paso 9: Crear triggers autom√°ticos
                self._create_automatic_triggers()
                
                # Paso 10: Crear √≠ndices de performance
                self._create_performance_indexes()
                
                # Paso 11: Migrar datos existentes
                self._migrate_existing_data()
                
                # Paso 12: Verificar integridad
                self._verify_migration()
                
                logger.info("‚úÖ MIGRACI√ìN COMPLETADA EXITOSAMENTE")
                logger.info("La base de datos ahora es una herramienta de inteligencia operacional completa.")
                
        except Exception as e:
            logger.error(f"‚ùå ERROR EN MIGRACI√ìN: {str(e)}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            raise
    
    def _create_backup(self):
        """Crear backup de seguridad antes de la migraci√≥n."""
        logger.info("üìã Creando backup de seguridad...")
        
        backup_queries = [
            "CREATE TABLE IF NOT EXISTS backup_edp AS SELECT * FROM edp;",
            "CREATE TABLE IF NOT EXISTS backup_projects AS SELECT * FROM projects;",
            "CREATE TABLE IF NOT EXISTS backup_cost_header AS SELECT * FROM cost_header;",
            "CREATE TABLE IF NOT EXISTS backup_cost_lines AS SELECT * FROM cost_lines;"
        ]
        
        for query in backup_queries:
            try:
                db.session.execute(query)
                db.session.commit()
            except Exception as e:
                logger.warning(f"Backup query fall√≥ (puede ser normal): {str(e)}")
        
        logger.info("‚úÖ Backup de seguridad creado")
    
    def _fix_monetary_types(self):
        """CR√çTICO: Corregir tipos monetarios de BIGINT a DECIMAL para precisi√≥n financiera."""
        logger.info("üí∞ CORRIGIENDO TIPOS MONETARIOS CR√çTICOS...")
        
        # Detectar si estamos en SQLite o PostgreSQL
        is_sqlite = 'sqlite' in str(db.engine.url).lower()
        
        if is_sqlite:
            # SQLite: recrear tablas con tipos correctos
            monetary_fixes = [
                """
                -- Crear nueva tabla EDP con tipos correctos
                CREATE TABLE edp_new (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    n_edp INTEGER NOT NULL,
                    proyecto VARCHAR(100),
                    cliente VARCHAR(100),
                    gestor VARCHAR(100),
                    jefe_proyecto VARCHAR(100),
                    mes VARCHAR(100),
                    fecha_emision DATETIME,
                    fecha_envio_cliente DATETIME,
                    monto_propuesto DECIMAL(15,2),
                    monto_aprobado DECIMAL(15,2),
                    fecha_estimada_pago DATETIME,
                    conformidad_enviada BOOLEAN,
                    n_conformidad VARCHAR(100),
                    fecha_conformidad DATETIME,
                    estado VARCHAR(100),
                    observaciones TEXT,
                    registrado_por VARCHAR(100),
                    estado_detallado VARCHAR(100),
                    fecha_registro DATETIME,
                    motivo_no_aprobado VARCHAR(100),
                    tipo_falla VARCHAR(100),
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
                );
                """,
                "INSERT INTO edp_new SELECT * FROM edp;",
                "DROP TABLE edp;",
                "ALTER TABLE edp_new RENAME TO edp;",
                
                """
                -- Crear nueva tabla projects con tipos correctos
                CREATE TABLE projects_new (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    project_id VARCHAR(100) UNIQUE NOT NULL,
                    proyecto VARCHAR(100),
                    cliente VARCHAR(100),
                    gestor VARCHAR(100),
                    jefe_proyecto VARCHAR(100),
                    fecha_inicio DATE,
                    fecha_fin_prevista DATE,
                    monto_contrato DECIMAL(15,2),
                    moneda VARCHAR(100),
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
                );
                """,
                "INSERT INTO projects_new SELECT * FROM projects;",
                "DROP TABLE projects;",
                "ALTER TABLE projects_new RENAME TO projects;",
                
                """
                -- Crear nueva tabla cost_header con tipos correctos
                CREATE TABLE cost_header_new (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    cost_id INTEGER UNIQUE NOT NULL,
                    project_id VARCHAR(100),
                    proveedor VARCHAR(100),
                    factura VARCHAR(100),
                    fecha_factura DATE,
                    fecha_recepcion DATE,
                    fecha_vencimiento DATE,
                    fecha_pago DATE,
                    importe_bruto DECIMAL(15,2),
                    importe_neto DECIMAL(15,2),
                    moneda VARCHAR(100),
                    estado_costo VARCHAR(100),
                    tipo_costo VARCHAR(100),
                    detalle_costo VARCHAR(100),
                    detalle_especifico_costo VARCHAR(100),
                    responsable_registro VARCHAR(100),
                    url_respaldo VARCHAR(200),
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
                );
                """,
                "INSERT INTO cost_header_new SELECT * FROM cost_header;",
                "DROP TABLE cost_header;",
                "ALTER TABLE cost_header_new RENAME TO cost_header;"
            ]
        else:
            # PostgreSQL: usar ALTER TABLE
            monetary_fixes = [
                "ALTER TABLE edp ALTER COLUMN monto_propuesto TYPE DECIMAL(15,2);",
                "ALTER TABLE edp ALTER COLUMN monto_aprobado TYPE DECIMAL(15,2);",
                "ALTER TABLE projects ALTER COLUMN monto_contrato TYPE DECIMAL(15,2);",
                "ALTER TABLE cost_header ALTER COLUMN importe_bruto TYPE DECIMAL(15,2);",
                "ALTER TABLE cost_header ALTER COLUMN importe_neto TYPE DECIMAL(15,2);",
                "ALTER TABLE cost_lines ALTER COLUMN precio_unitario TYPE DECIMAL(15,2);",
                "ALTER TABLE cost_lines ALTER COLUMN subtotal TYPE DECIMAL(15,2);"
            ]
        
        for query in monetary_fixes:
            try:
                db.session.execute(query)
                db.session.commit()
                logger.info(f"‚úÖ Ejecutado: {query[:50]}...")
            except Exception as e:
                logger.error(f"‚ùå Error en query monetario: {str(e)}")
                # Continuar con el resto de queries
        
        logger.info("‚úÖ Tipos monetarios corregidos - Precisi√≥n financiera asegurada")
    
    def _add_temporal_tracking_fields(self):
        """Agregar campos de tracking temporal granular a la tabla EDP."""
        logger.info("‚è±Ô∏è  AGREGANDO CAMPOS DE TRACKING TEMPORAL GRANULAR...")
        
        temporal_fields = [
            "ALTER TABLE edp ADD COLUMN fecha_aprobacion_interna DATETIME;",
            "ALTER TABLE edp ADD COLUMN fecha_reenvio_cliente DATETIME;",
            "ALTER TABLE edp ADD COLUMN numero_revisiones INTEGER DEFAULT 0;",
            "ALTER TABLE edp ADD COLUMN tiempo_revision_interna_horas INTEGER;",
            "ALTER TABLE edp ADD COLUMN dias_en_cliente INTEGER;",
            "ALTER TABLE edp ADD COLUMN fecha_ultimo_seguimiento DATETIME;",
            "ALTER TABLE edp ADD COLUMN numero_seguimientos INTEGER DEFAULT 0;",
            "ALTER TABLE edp ADD COLUMN prioridad VARCHAR(20) CHECK (prioridad IN ('ALTA', 'MEDIA', 'BAJA'));",
            "ALTER TABLE edp ADD COLUMN complejidad_tecnica VARCHAR(20) CHECK (complejidad_tecnica IN ('SIMPLE', 'MEDIA', 'COMPLEJA'));",
            "ALTER TABLE edp ADD COLUMN requiere_presentacion BOOLEAN DEFAULT FALSE;",
            "ALTER TABLE edp ADD COLUMN canal_envio VARCHAR(50);",
            "ALTER TABLE edp ADD COLUMN metodo_conformidad VARCHAR(50);",
            "ALTER TABLE edp ADD COLUMN usuario_seguimiento VARCHAR(100);"
        ]
        
        for field_query in temporal_fields:
            try:
                db.session.execute(field_query)
                db.session.commit()
                logger.info(f"‚úÖ Campo agregado: {field_query.split('ADD COLUMN')[1].split()[0]}")
            except Exception as e:
                logger.warning(f"Campo ya existe o error: {str(e)}")
        
        logger.info("‚úÖ Campos de tracking temporal agregados")
    
    def _create_edp_status_history_table(self):
        """CR√çTICA: Crear tabla de historial de estados para an√°lisis de cuellos de botella."""
        logger.info("üìä CREANDO TABLA CR√çTICA: EDP_STATUS_HISTORY...")
        
        create_history_table = """
        CREATE TABLE IF NOT EXISTS edp_status_history (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            edp_id INTEGER NOT NULL,
            estado_anterior VARCHAR(100),
            estado_nuevo VARCHAR(100),
            fecha_cambio DATETIME DEFAULT CURRENT_TIMESTAMP,
            usuario VARCHAR(100),
            comentario TEXT,
            tiempo_en_estado_anterior_horas INTEGER,
            trigger_cambio VARCHAR(100), -- MANUAL, AUTOMATICO, SISTEMA
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (edp_id) REFERENCES edp(id)
        );
        """
        
        try:
            db.session.execute(create_history_table)
            db.session.commit()
            logger.info("‚úÖ Tabla edp_status_history creada - An√°lisis de cuellos de botella habilitado")
        except Exception as e:
            logger.warning(f"Tabla ya existe o error: {str(e)}")
    
    def _create_client_profiles_table(self):
        """Crear tabla de perfiles de clientes para an√°lisis predictivo."""
        logger.info("üéØ CREANDO TABLA PREDICTIVA: CLIENT_PROFILES...")
        
        create_profiles_table = """
        CREATE TABLE IF NOT EXISTS client_profiles (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            cliente VARCHAR(100) UNIQUE NOT NULL,
            promedio_dias_conformidad DECIMAL(5,2),
            tasa_aprobacion_porcentaje DECIMAL(5,2),
            numero_total_edps INTEGER DEFAULT 0,
            monto_total_aprobado DECIMAL(15,2) DEFAULT 0,
            ultimo_edp_fecha DATETIME,
            nivel_riesgo_calculado VARCHAR(20),
            patron_pago VARCHAR(50), -- RAPIDO, NORMAL, LENTO
            requiere_seguimiento_especial BOOLEAN DEFAULT FALSE,
            notas_comportamiento TEXT,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
        );
        """
        
        try:
            db.session.execute(create_profiles_table)
            db.session.commit()
            logger.info("‚úÖ Tabla client_profiles creada - An√°lisis predictivo habilitado")
        except Exception as e:
            logger.warning(f"Tabla ya existe o error: {str(e)}")
    
    def _enhance_projects_table(self):
        """Enriquecer tabla de proyectos con campos para an√°lisis predictivo."""
        logger.info("üèóÔ∏è  ENRIQUECIENDO TABLA PROJECTS...")
        
        project_enhancements = [
            "ALTER TABLE projects ADD COLUMN tipo_cliente VARCHAR(50) CHECK (tipo_cliente IN ('PUBLICO', 'PRIVADO', 'ONG'));",
            "ALTER TABLE projects ADD COLUMN industria_cliente VARCHAR(100);",
            "ALTER TABLE projects ADD COLUMN nivel_madurez_cliente VARCHAR(20) CHECK (nivel_madurez_cliente IN ('NUEVO', 'RECURRENTE', 'ESTRATEGICO'));",
            "ALTER TABLE projects ADD COLUMN sla_respuesta_dias INTEGER;",
            "ALTER TABLE projects ADD COLUMN ejecutivo_cuenta VARCHAR(100);",
            "ALTER TABLE projects ADD COLUMN estado_proyecto VARCHAR(50) DEFAULT 'ACTIVO';",
            "ALTER TABLE projects ADD COLUMN margen_objetivo_porcentaje DECIMAL(5,2);"
        ]
        
        for enhancement in project_enhancements:
            try:
                db.session.execute(enhancement)
                db.session.commit()
                logger.info(f"‚úÖ Mejora agregada: {enhancement.split('ADD COLUMN')[1].split()[0]}")
            except Exception as e:
                logger.warning(f"Campo ya existe o error: {str(e)}")
        
        logger.info("‚úÖ Tabla projects enriquecida")
    
    def _enhance_cost_tables(self):
        """Mejorar tablas de costos para mejor clasificaci√≥n."""
        logger.info("üíº MEJORANDO TABLAS DE COSTOS...")
        
        cost_enhancements = [
            "ALTER TABLE cost_header ADD COLUMN categoria_principal VARCHAR(100);",
            "ALTER TABLE cost_header ADD COLUMN impacta_margen BOOLEAN DEFAULT TRUE;",
            "ALTER TABLE cost_header ADD COLUMN porcentaje_asignable_proyecto DECIMAL(5,2) DEFAULT 100.00;"
        ]
        
        for enhancement in cost_enhancements:
            try:
                db.session.execute(enhancement)
                db.session.commit()
                logger.info(f"‚úÖ Mejora de costos agregada: {enhancement.split('ADD COLUMN')[1].split()[0]}")
            except Exception as e:
                logger.warning(f"Campo ya existe o error: {str(e)}")
        
        logger.info("‚úÖ Tablas de costos mejoradas")
    
    def _create_kpi_snapshots_table(self):
        """Crear tabla de KPI snapshots para an√°lisis de tendencias temporales."""
        logger.info("üìà CREANDO TABLA DE TENDENCIAS: KPI_SNAPSHOTS...")
        
        create_kpi_table = """
        CREATE TABLE IF NOT EXISTS kpi_snapshots (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            fecha_snapshot DATE NOT NULL,
            dso_promedio DECIMAL(5,2),
            total_pendiente DECIMAL(15,2),
            total_aprobado_mes DECIMAL(15,2),
            numero_edps_activos INTEGER,
            tasa_aprobacion_porcentaje DECIMAL(5,2),
            tiempo_promedio_conformidad DECIMAL(5,2),
            clientes_activos INTEGER,
            proyectos_activos INTEGER,
            margen_bruto_porcentaje DECIMAL(5,2),
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(fecha_snapshot)
        );
        """
        
        try:
            db.session.execute(create_kpi_table)
            db.session.commit()
            logger.info("‚úÖ Tabla kpi_snapshots creada - An√°lisis de tendencias habilitado")
        except Exception as e:
            logger.warning(f"Tabla ya existe o error: {str(e)}")
    
    def _create_automatic_triggers(self):
        """Crear triggers autom√°ticos para mantener consistencia sin carga manual."""
        logger.info("ü§ñ CREANDO TRIGGERS AUTOM√ÅTICOS...")
        
        # Verificar si estamos en SQLite o PostgreSQL
        is_sqlite = 'sqlite' in str(db.engine.url).lower()
        
        if is_sqlite:
            # SQLite triggers
            sqlite_triggers = [
                """
                CREATE TRIGGER IF NOT EXISTS update_dias_en_cliente
                AFTER UPDATE ON edp
                FOR EACH ROW
                WHEN NEW.fecha_conformidad IS NOT NULL AND NEW.fecha_envio_cliente IS NOT NULL
                BEGIN
                    UPDATE edp SET 
                        dias_en_cliente = CAST((julianday(NEW.fecha_conformidad) - julianday(NEW.fecha_envio_cliente)) AS INTEGER),
                        updated_at = CURRENT_TIMESTAMP
                    WHERE id = NEW.id;
                END;
                """,
                
                """
                CREATE TRIGGER IF NOT EXISTS log_status_change
                AFTER UPDATE ON edp
                FOR EACH ROW
                WHEN OLD.estado != NEW.estado
                BEGIN
                    INSERT INTO edp_status_history (edp_id, estado_anterior, estado_nuevo, usuario, trigger_cambio)
                    VALUES (NEW.id, OLD.estado, NEW.estado, NEW.registrado_por, 'AUTOMATICO');
                END;
                """
            ]
            
            for trigger in sqlite_triggers:
                try:
                    db.session.execute(trigger)
                    db.session.commit()
                    logger.info("‚úÖ Trigger SQLite creado")
                except Exception as e:
                    logger.warning(f"Trigger ya existe o error: {str(e)}")
        
        else:
            # PostgreSQL triggers
            postgres_triggers = [
                """
                CREATE OR REPLACE FUNCTION update_dias_en_cliente()
                RETURNS TRIGGER AS $$
                BEGIN
                    IF NEW.fecha_conformidad IS NOT NULL AND NEW.fecha_envio_cliente IS NOT NULL THEN
                        NEW.dias_en_cliente = EXTRACT(DAY FROM NEW.fecha_conformidad - NEW.fecha_envio_cliente);
                    END IF;
                    NEW.updated_at = CURRENT_TIMESTAMP;
                    RETURN NEW;
                END;
                $$ LANGUAGE plpgsql;
                """,
                
                """
                CREATE TRIGGER trigger_update_dias_en_cliente
                    BEFORE UPDATE ON edp
                    FOR EACH ROW
                    EXECUTE FUNCTION update_dias_en_cliente();
                """,
                
                """
                CREATE OR REPLACE FUNCTION log_status_change()
                RETURNS TRIGGER AS $$
                BEGIN
                    IF OLD.estado != NEW.estado THEN
                        INSERT INTO edp_status_history (edp_id, estado_anterior, estado_nuevo, usuario, trigger_cambio)
                        VALUES (NEW.id, OLD.estado, NEW.estado, NEW.registrado_por, 'AUTOMATICO');
                    END IF;
                    RETURN NEW;
                END;
                $$ LANGUAGE plpgsql;
                """,
                
                """
                CREATE TRIGGER trigger_log_status_change
                    AFTER UPDATE ON edp
                    FOR EACH ROW
                    EXECUTE FUNCTION log_status_change();
                """
            ]
            
            for trigger in postgres_triggers:
                try:
                    db.session.execute(trigger)
                    db.session.commit()
                    logger.info("‚úÖ Trigger PostgreSQL creado")
                except Exception as e:
                    logger.warning(f"Trigger ya existe o error: {str(e)}")
        
        logger.info("‚úÖ Triggers autom√°ticos creados - Consistencia garantizada")
    
    def _create_performance_indexes(self):
        """Crear √≠ndices para optimizar performance de consultas cr√≠ticas."""
        logger.info("‚ö° CREANDO √çNDICES DE PERFORMANCE...")
        
        performance_indexes = [
            "CREATE INDEX IF NOT EXISTS idx_edp_fecha_conformidad ON edp(fecha_conformidad);",
            "CREATE INDEX IF NOT EXISTS idx_edp_prioridad ON edp(prioridad);",
            "CREATE INDEX IF NOT EXISTS idx_edp_complejidad ON edp(complejidad_tecnica);",
            "CREATE INDEX IF NOT EXISTS idx_edp_cliente ON edp(cliente);",
            "CREATE INDEX IF NOT EXISTS idx_edp_estado ON edp(estado);",
            "CREATE INDEX IF NOT EXISTS idx_edp_dias_en_cliente ON edp(dias_en_cliente);",
            "CREATE INDEX IF NOT EXISTS idx_edp_status_history_edp_id ON edp_status_history(edp_id);",
            "CREATE INDEX IF NOT EXISTS idx_edp_status_history_fecha ON edp_status_history(fecha_cambio);",
            "CREATE INDEX IF NOT EXISTS idx_client_profiles_cliente ON client_profiles(cliente);",
            "CREATE INDEX IF NOT EXISTS idx_client_profiles_patron_pago ON client_profiles(patron_pago);",
            "CREATE INDEX IF NOT EXISTS idx_kpi_snapshots_fecha ON kpi_snapshots(fecha_snapshot);",
            "CREATE INDEX IF NOT EXISTS idx_projects_tipo_cliente ON projects(tipo_cliente);",
            "CREATE INDEX IF NOT EXISTS idx_projects_nivel_madurez ON projects(nivel_madureza_cliente);"
        ]
        
        for index in performance_indexes:
            try:
                db.session.execute(index)
                db.session.commit()
                logger.info(f"‚úÖ √çndice creado: {index.split('ON')[1].split('(')[0].strip()}")
            except Exception as e:
                logger.warning(f"√çndice ya existe o error: {str(e)}")
        
        logger.info("‚úÖ √çndices de performance creados - Consultas optimizadas")
    
    def _migrate_existing_data(self):
        """Migrar y enriquecer datos existentes con nueva informaci√≥n."""
        logger.info("üîÑ MIGRANDO Y ENRIQUECIENDO DATOS EXISTENTES...")
        
        try:
            # Inicializar campos de tracking temporal basado en datos existentes
            migration_queries = [
                # Calcular d√≠as en cliente para EDPs existentes
                """
                UPDATE edp 
                SET dias_en_cliente = CAST((julianday(fecha_conformidad) - julianday(fecha_envio_cliente)) AS INTEGER)
                WHERE fecha_conformidad IS NOT NULL 
                AND fecha_envio_cliente IS NOT NULL 
                AND dias_en_cliente IS NULL;
                """,
                
                # Asignar prioridad basada en monto
                """
                UPDATE edp 
                SET prioridad = CASE 
                    WHEN monto_aprobado > 10000000 THEN 'ALTA'
                    WHEN monto_aprobado > 5000000 THEN 'MEDIA'
                    ELSE 'BAJA'
                END
                WHERE prioridad IS NULL AND monto_aprobado IS NOT NULL;
                """,
                
                # Crear perfiles iniciales de clientes
                """
                INSERT OR IGNORE INTO client_profiles (
                    cliente, 
                    numero_total_edps, 
                    monto_total_aprobado, 
                    ultimo_edp_fecha,
                    promedio_dias_conformidad
                )
                SELECT 
                    cliente,
                    COUNT(*) as numero_total_edps,
                    SUM(COALESCE(monto_aprobado, 0)) as monto_total_aprobado,
                    MAX(fecha_conformidad) as ultimo_edp_fecha,
                    AVG(dias_en_cliente) as promedio_dias_conformidad
                FROM edp 
                WHERE cliente IS NOT NULL 
                GROUP BY cliente;
                """,
                
                # Calcular patrones de pago
                """
                UPDATE client_profiles 
                SET patron_pago = CASE 
                    WHEN promedio_dias_conformidad <= 15 THEN 'RAPIDO'
                    WHEN promedio_dias_conformidad <= 30 THEN 'NORMAL'
                    ELSE 'LENTO'
                END
                WHERE promedio_dias_conformidad IS NOT NULL;
                """
            ]
            
            for query in migration_queries:
                try:
                    db.session.execute(query)
                    db.session.commit()
                    logger.info(f"‚úÖ Datos migrados: {query[:50]}...")
                except Exception as e:
                    logger.warning(f"Error en migraci√≥n de datos: {str(e)}")
            
            logger.info("‚úÖ Datos existentes migrados y enriquecidos")
            
        except Exception as e:
            logger.error(f"‚ùå Error en migraci√≥n de datos: {str(e)}")
    
    def _verify_migration(self):
        """Verificar que la migraci√≥n se complet√≥ correctamente."""
        logger.info("üîç VERIFICANDO INTEGRIDAD DE LA MIGRACI√ìN...")
        
        verification_queries = [
            "SELECT COUNT(*) as total_edps FROM edp;",
            "SELECT COUNT(*) as total_history FROM edp_status_history;",
            "SELECT COUNT(*) as total_profiles FROM client_profiles;",
            "SELECT COUNT(*) as total_kpi_snapshots FROM kpi_snapshots;",
            "SELECT COUNT(*) as edps_with_priority FROM edp WHERE prioridad IS NOT NULL;",
            "SELECT COUNT(*) as edps_with_temporal_data FROM edp WHERE dias_en_cliente IS NOT NULL;"
        ]
        
        verification_results = {}
        for query in verification_queries:
            try:
                result = db.session.execute(query).fetchone()
                metric_name = query.split('as ')[1].split(' FROM')[0]
                verification_results[metric_name] = result[0] if result else 0
                logger.info(f"‚úÖ {metric_name}: {verification_results[metric_name]}")
            except Exception as e:
                logger.warning(f"Error en verificaci√≥n: {str(e)}")
        
        # Verificar que tenemos mejoras
        if verification_results.get('edps_with_priority', 0) > 0:
            logger.info("‚úÖ Campos de prioridad funcionando")
        
        if verification_results.get('total_profiles', 0) > 0:
            logger.info("‚úÖ Perfiles de clientes creados")
        
        logger.info("üéâ VERIFICACI√ìN COMPLETADA - Base de datos transformada exitosamente")


def main():
    """Funci√≥n principal para ejecutar la migraci√≥n."""
    try:
        # Crear aplicaci√≥n Flask
        app = Flask(__name__)
        
        # Cargar configuraci√≥n
        config = get_config()
        app.config.from_object(config)
        
        # Inicializar extensiones
        db.init_app(app)
        
        # Ejecutar migraci√≥n
        migration = DatabaseEnhancementMigration(app)
        migration.run_migration()
        
        print("\n" + "="*80)
        print("üéØ MIGRACI√ìN COMPLETADA EXITOSAMENTE")
        print("="*80)
        print("Tu base de datos ahora incluye:")
        print("‚úÖ Tipos monetarios DECIMAL para precisi√≥n financiera")
        print("‚úÖ Historial autom√°tico de cambios de estado")
        print("‚úÖ Perfiles de clientes para an√°lisis predictivo")
        print("‚úÖ Tracking temporal granular de procesos")
        print("‚úÖ KPI snapshots para an√°lisis de tendencias")
        print("‚úÖ Triggers autom√°ticos para consistencia")
        print("‚úÖ √çndices optimizados para performance")
        print("\nüöÄ Pagora MVP ahora es una herramienta de inteligencia operacional completa!")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå ERROR EN MIGRACI√ìN: {str(e)}")
        print(f"Traceback completo: {traceback.format_exc()}")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)